{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/BGsI2GRU7M+b5dbwCa+J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"ByRzkJwlEhKt","executionInfo":{"status":"ok","timestamp":1719314877509,"user_tz":-330,"elapsed":504,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","source":["#Load the IMDB dataset\n","vocab_size= 1000      #size of the vocabulary\n","max_len= 200          #maximum length of each review (truncate longer, pad shorter)\n","embedding_dim= 128    #Dimension of word embedding\n","\n","(Xtrain,ytrain), (Xtest,ytest) =imdb.load_data(num_words=vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmcgDMgsG7O2","executionInfo":{"status":"ok","timestamp":1719315136258,"user_tz":-330,"elapsed":4713,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}},"outputId":"3891a2e2-9bc5-4044-9433-21751e563ebd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["### Word Enberding"],"metadata":{"id":"Xxxm_MM-NU6s"}},{"cell_type":"code","source":["# Get the word index dictionary\n","word_index = imdb.get_word_index()\n","\n","# Invert the dictionary to map indices to words\n","index_to_word = {index + 3: word for word, index in word_index.items()}\n","index_to_word[0] = \"<PAD>\"\n","index_to_word[1] = \"<START>\"\n","index_to_word[2] = \"<UNK>\"\n","index_to_word[3] = \"<UNUSED>\"\n","\n","# Decode a review\n","def decode_review(encoded_review):\n","    return ' '.join([index_to_word.get(i, '?') for i in encoded_review])\n","\n","# Decode the first review\n","print(\"First review (decoded):\", decode_review(Xtrain[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsAHwZtZKubL","executionInfo":{"status":"ok","timestamp":1719315880555,"user_tz":-330,"elapsed":1067,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}},"outputId":"72b2f770-022b-4ff9-e6b5-d6045f336188"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["First review (decoded): <START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\n"]}]},{"cell_type":"code","source":["#Pad sequences to ensure uniform length for RNN input\n","\n","Xtrain=pad_sequences(Xtrain,maxlen=max_len)\n","Xtest=pad_sequences(Xtest, maxlen=max_len)"],"metadata":{"id":"dzo284SmKxtq","executionInfo":{"status":"ok","timestamp":1719316358049,"user_tz":-330,"elapsed":486,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#Define RNN model using Tensorflow\n","\n","model=tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n","    tf.keras.layers.LSTM(64),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","\n","#compile the model\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","#print model summary\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6NzSWxzLi51","executionInfo":{"status":"ok","timestamp":1719317511751,"user_tz":-330,"elapsed":866,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}},"outputId":"71b5dcd9-827d-4122-a921-db171f161a73"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 200, 128)          128000    \n","                                                                 \n"," lstm_3 (LSTM)               (None, 64)                49408     \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 177473 (693.25 KB)\n","Trainable params: 177473 (693.25 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#Train the model\n","\n","model.fit(Xtrain,ytrain, epochs=3, batch_size=128, validation_data=(Xtest,ytest))\n","\n","\n","#Evaluate the model\n","\n","loss,accuracy=model.evaluate(Xtest,ytest)\n","print(loss,accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Rj5uJcURcHU","executionInfo":{"status":"ok","timestamp":1719317897562,"user_tz":-330,"elapsed":384190,"user":{"displayName":"MELBIN MATHEW","userId":"12383988176266093593"}},"outputId":"9552f32c-a2c7-4197-d188-406aa376a6f0"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","196/196 [==============================] - 105s 521ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.3690 - val_accuracy: 0.8427\n","Epoch 2/3\n","196/196 [==============================] - 119s 610ms/step - loss: 0.3414 - accuracy: 0.8547 - val_loss: 0.3325 - val_accuracy: 0.8579\n","Epoch 3/3\n","196/196 [==============================] - 119s 606ms/step - loss: 0.3218 - accuracy: 0.8650 - val_loss: 0.3429 - val_accuracy: 0.8503\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3429 - accuracy: 0.8503\n","0.3429221510887146 0.8503199815750122\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xyRgKFjkTaCc"},"execution_count":null,"outputs":[]}]}